---
title: "Yolov8ä¸­æ·»åŠ SAæ³¨æ„åŠ›æœºåˆ¶"
excerpt: "è®°å½•äº†åœ¨Yolov8ç½‘ç»œä¸­æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶æ¨¡å—çš„è¿‡ç¨‹"
author: "Wang Eden"
date: "2025-05-26"
tags: ["è®¡ç®—æœºè§†è§‰", "æ·±åº¦å­¦ä¹ ", "Yolov8"]
category: "è§†è§‰"
cover: "/imgs/articleCover/Yolov8ä¸­æ·»åŠ SAæ³¨æ„åŠ›æœºåˆ¶.jpg"
views: 2437
featured: false
slug: "Yolov8ä¸­æ·»åŠ SAæ³¨æ„åŠ›æœºåˆ¶"

---
###### æ­¥éª¤

1.å¸è½½åº“ä¸­çš„ultralytics
```bash
pip uninstall ultralytics
pip uninstall ultralytics-thop
```

2.æ‰¾åˆ°ultralytics/ultralytics/nn/modulesè·¯å¾„
åˆ›å»ºSA.py
å†…å®¹ä¸ºï¼š
```Python
import numpy as np
import torch
from torch import nn
from torch.nn import init
from torch.nn.parameter import Parameter

class ShuffleAttention(nn.Module):
Â  Â  def __init__(self, channel=512, out_channel=512, reduction=16, G=8):
Â  Â  Â  Â  super().__init__()
Â  Â  Â  Â  self.G = G
Â  Â  Â  Â  self.channel = channel
Â  Â  Â  Â  self.avg_pool = nn.AdaptiveAvgPool2d(1)
Â  Â  Â  Â  self.gn = nn.GroupNorm(channel // (2 * G), channel // (2 * G))
Â  Â  Â  Â  self.cweight = Parameter(torch.zeros(1, channel // (2 * G), 1, 1))
Â  Â  Â  Â  self.cbias = Parameter(torch.ones(1, channel // (2 * G), 1, 1))
Â  Â  Â  Â  self.sweight = Parameter(torch.zeros(1, channel // (2 * G), 1, 1))
Â  Â  Â  Â  self.sbias = Parameter(torch.ones(1, channel // (2 * G), 1, 1))
Â  Â  Â  Â  self.sigmoid = nn.Sigmoid()
Â  Â  def init_weights(self):
Â  Â  Â  Â  for m in self.modules():
Â  Â  Â  Â  Â  Â  if isinstance(m, nn.Conv2d):
Â  Â  Â  Â  Â  Â  Â  Â  init.kaiming_normal_(m.weight, mode='fan_out')
Â  Â  Â  Â  Â  Â  Â  Â  if m.bias is not None:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  init.constant_(m.bias, 0)
Â  Â  Â  Â  Â  Â  elif isinstance(m, nn.BatchNorm2d):
Â  Â  Â  Â  Â  Â  Â  Â  init.constant_(m.weight, 1)
Â  Â  Â  Â  Â  Â  Â  Â  init.constant_(m.bias, 0)
Â  Â  Â  Â  Â  Â  elif isinstance(m, nn.Linear):
Â  Â  Â  Â  Â  Â  Â  Â  init.normal_(m.weight, std=0.001)
Â  Â  Â  Â  Â  Â  Â  Â  if m.bias is not None:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  init.constant_(m.bias, 0)
Â  Â  @staticmethod
Â  Â  def channel_shuffle(x, groups):
Â  Â  Â  Â  b, c, h, w = x.shape
Â  Â  Â  Â  x = x.reshape(b, groups, -1, h, w)
Â  Â  Â  Â  x = x.permute(0, 2, 1, 3, 4)
Â  Â  Â  Â  # flatten
Â  Â  Â  Â  x = x.reshape(b, -1, h, w)
Â  Â  Â  Â  return x
Â  Â  def forward(self, x):
Â  Â  Â  Â  b, c, h, w = x.size()
Â  Â  Â  Â  # group into subfeatures
Â  Â  Â  Â  x = x.view(b * self.G, -1, h, w) Â # bs*G,c//G,h,w
Â  Â  Â  Â  # channel_split
Â  Â  Â  Â  x_0, x_1 = x.chunk(2, dim=1) Â # bs*G,c//(2*G),h,w
Â  Â  Â  Â  # channel attention
Â  Â  Â  Â  x_channel = self.avg_pool(x_0) Â # bs*G,c//(2*G),1,1
Â  Â  Â  Â  x_channel = self.cweight * x_channel + self.cbias Â # bs*G,c//(2*G),1,1
Â  Â  Â  Â  x_channel = x_0 * self.sigmoid(x_channel)
Â  Â  Â  Â  # spatial attention
Â  Â  Â  Â  x_spatial = self.gn(x_1) Â # bs*G,c//(2*G),h,w
Â  Â  Â  Â  x_spatial = self.sweight * x_spatial + self.sbias Â # bs*G,c//(2*G),h,w
Â  Â  Â  Â  x_spatial = x_1 * self.sigmoid(x_spatial) Â # bs*G,c//(2*G),h,w
Â  Â  Â  Â  # concatenate along channel axis
Â  Â  Â  Â  out = torch.cat([x_channel, x_spatial], dim=1) Â # bs*G,c//G,h,w
Â  Â  Â  Â  out = out.contiguous().view(b, -1, h, w)
Â  Â  Â  Â  # channel shuffle
Â  Â  Â  Â  out = self.channel_shuffle(out, 2)
Â  Â  Â  Â  return out
```

3.åœ¨åŒä¸€è·¯å¾„ä¸‹ä¿®æ”¹init.pyæ–‡ä»¶
æ·»åŠ 
```Python
from .SA import ShuffleAttention
```
å¹¶ä¿®æ”¹__all__å˜é‡
```Python
å°† "ShuffleAttention" åŠ åˆ° __all__ä¸­
```

4.æ‰¾åˆ°ultralytics/ultralytics/nn/tasks.pyæ–‡ä»¶
æ·»åŠ 
```Python
from ultralytics.nn.modules import ShuffleAttention
```
å¹¶æ‰¾åˆ°è¿™ä¸€è¡Œä»£ç 
```Python
elif m is torch.nn.BatchNorm2d:
	args = [ch[f]]
```
åœ¨å…¶ä¸Šæ–¹æ·»åŠ ä»¥ä¸‹ä»£ç 
```Python
elif m is ShuffleAttention: # add shuffle attention
	c1, c2 = ch[f], args[0]
	if c2 != nc: Â # if c2 not equal to number of classes (i.e. for Classify() output) Â 
		c2 = make_divisible(min(c2, max_channels) * width, 8)
	args = [c1, c2, *args[1:]]
```

5.ä¿®æ”¹yamlé…ç½®æ–‡ä»¶
å¤åˆ¶ä¸€ä»½ultralytics/ultralytics/cfg/models/v8/yolov8.yamlæ–‡ä»¶
å‘½åä¸ºyolov8-SA.yaml,å¹¶ä¿®æ”¹ä¸ºä»¥ä¸‹å†…å®¹ï¼Œä¹Ÿå¯ä»¥è‡ªè¡Œä¿®æ”¹ã€‚
```yaml
# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
# Ultralytics YOLOv8 object detection model with P3/8 - P5/32 outputs
# Model docs: https://docs.ultralytics.com/models/yolov8
# Task docs: https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
Â  # [depth, width, max_channels]
Â  n: [0.33, 0.25, 1024] # YOLOv8n summary: 129 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPS
Â  s: [0.33, 0.50, 1024] # YOLOv8s summary: 129 layers, 11166560 parameters, 11166544 gradients, 28.8 GFLOPS
Â  m: [0.67, 0.75, 768] # YOLOv8m summary: 169 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPS
Â  l: [1.00, 1.00, 512] # YOLOv8l summary: 209 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPS
Â  x: [1.00, 1.25, 512] # YOLOv8x summary: 209 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPS
  
# YOLOv8.0n backbone
backbone:
Â  # [from, repeats, module, args]
Â  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
Â  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
Â  - [-1, 3, C2f, [128, True]]
Â  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
Â  - [-1, 6, C2f, [256, True]]
Â  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
Â  - [-1, 6, C2f, [512, True]]
Â  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
Â  - [-1, 3, C2f, [1024, True]]
Â  - [-1, 3, ShuffleAttention, [1024]]
Â  - [-1, 1, SPPF, [1024, 5]] # 9

# YOLOv8.0n head
head:
Â  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
Â  - [[-1, 6], 1, Concat, [1]] # cat backbone P4
Â  - [-1, 3, C2f, [512]] # 12
  
Â  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
Â  - [[-1, 4], 1, Concat, [1]] # cat backbone P3
Â  - [-1, 3, C2f, [256]] # 15 (P3/8-small)

Â  - [-1, 1, ShuffleAttention, [256, 16, 8]]
Â  - [-1, 1, Conv, [256, 3, 2]]
Â  - [[-1, 12], 1, Concat, [1]] # cat head P4
Â  - [-1, 3, C2f, [512]] # 18 (P4/16-medium)
  
Â  - [-1, 1, ShuffleAttention, [512, 16, 8]]
Â  - [-1, 1, Conv, [512, 3, 2]]
Â  - [[-1, 9], 1, Concat, [1]] # cat head P5
Â  - [-1, 3, C2f, [1024]] # 21 (P5/32-large)

Â  - [[15, 18, 21], 1, Detect, [nc]] # Detect(P3, P4, P5)
```

6.ä¿®æ”¹è®­ç»ƒè„šæœ¬ï¼š
æ³¨é‡Š # model = YOLO("pre_weight/yolov8n.pt")
è¯¥ä»£ç ä¼šååºåˆ—åŒ–æ¨¡å‹ï¼Œä½¿ä¿®æ”¹åçš„æ¨¡å‹å¤±æ•ˆ
æ­£ç¡®åŠ è½½é¢„è®­ç»ƒæƒé‡çš„æ–¹æ³•æ˜¯ï¼š
```
import torch
# Load a model
model = YOLO("ultralytics/cfg/models/v8/YOLOv8-SA.yaml") Â # build a new model from scratch
ckpt = torch.load("pre_weight/yolov8n.pt", map_location="cpu")
state = ckpt["model"].float().state_dict()
model.model.load_state_dict(state, strict=False) Â  Â # åªåŒ¹é…åŒåå±‚
```
